[experiment]
model_class_name =  ConvRNN
reader_class_name = BBCIDataReader
working_dir = /home/chrabasp/EEG_Results/BBCI_BO
verbose = 1
budget_decoder_class_name = BBCIBudgetDecoder

[model]
rnn_hidden_size = 10
rnn_num_layers = 1
rnn_cell_type = GRU
use_context = 0
dropout_i = 0.0
dropout_f = 0.2
dropout_h = 0.5
rnn_normalization = none
skip_mode = none
rnn_initial_state = zero
skip_first = 1
skip_last = 0
features_per_channel = 25
time_kernel_size = 40
merged_channels = 40
pooling_size = 75
pooling_stride = 15
cnn_batch_norm = 1
lasso_selection = 0.0

[data_reader]
data_path = /home/schirrmr/data/
normalization_type = exponential
readers_count = 3
batch_size = 64
sequence_size = 512
# With 0 we indicate that we want to keep it the same as train sequence_size
validation_sequence_size = 512
validation_batch_size = 0
balanced = 1
random_mode = 2
continuous = 1
limit_examples = 0
limit_duration = 0
forget_state = 1
cv_n = 5
cv_k = 4
subject_name = BhNoMoSc1S001
load_sensor_names = FC5,FC1,FC2,FC6,C3,C4,CP5,CP1,CP2,CP6,FC3,FCz,FC4,C5,C1,C2,C6,CP3,CPz,CP4,FFC5h,FFC3h,FFC4h,FFC6h,FCC5h,FCC3h,FCC4h,FCC6h,CCP5h,CCP3h,CCP4h,CCP6h,CPP5h,CPP3h,CPP4h,CPP6h,FFC1h,FFC2h,FCC1h,FCC2h,CCP1h,CCP2h,CPP1h,CPP2h
segment_ival_ms_start = -500
segment_ival_ms_end = 4000


[model_trainer]
budget = 5
budget_type = minute
metrics_class = MetricsClassification
lr = 0.001
l2_decay = 0.0002
weight_decay = 0.0001
objective_type = CrossEntropy_last
cosine_decay = 1
optimizer = ExtendedAdam
metrics_skip_first = 0

[bayesian_optimizer]
config_space_file = config/hgd_dataset/split_convolution_rnn.pcs
bo_loss = log_acc_all
bo_loss_type = maximize
n_iterations = 1000
eta = 3
min_budget = 1
max_budget = 3

[config_generator]
min_points_in_model = 10
top_n_percent = 15
num_samples = 500
random_fraction = 0.2
bandwidth_factor = 3
